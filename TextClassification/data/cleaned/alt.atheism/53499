b'' b'' b'(about my reply)' b'' b' diplomatic b'' b'it a society that is constantly on the verge of flaming, usenet, diplomacy' b"is the best way to ensure the voice of reason gets through, isn't it?" b'' b" i realize i'm fighting occam's razor in this argument, so i'll try to" b' explain why i feel a mind is necessary.' b'' b'kevin, unfortunately you are now delving into field i know too little' b'about, algorithms. your reasoning, as i see it, is very much along the' b"lines of roger penrose, who claimed that mathematical 'insight' cannot" b"be algorithmic in his book _the emperor's new mind: concerning" b"computers, minds, and the laws of physics_. however, penrose's" b'claim that he _has_ mathematical insight, or your similar claim' b'that wavefunctions collapse only when we consciously take a look,' b'could be just illusions.' b'' b'we are obviouslu taking very different viewpoints i try to ponder' b'on the problem of consciousness from an evolutionary perspective,' b'realising that it might not be anything special, but certainly' b'useful. thinking back of what i wrote, do you think worms have minds' b'or not? they are able to experience pain, at least they behave' b'just like that. yet it is conceivable that we might some day' b'in the future perform a "total synthesis of c. elegans" from' b'the elements. would such a worm have a mind?' b'' b" firstly, i'm not impressed with the ability of algorithms. they're" b' great at solving problems once the method has been worked out, but not' b' at working out the method itself.' b'' b'this is true to some extent. however, i do not think that our brains' b'work like computers, at all. in fact, there is substantial evidence' b'(skarda, skarda freeman that brains work more or less' b'chaotically, generating enough randomness for mental states to evolve.' b'our brains work much like genetic algorithm generators, i suppose.' b'' b' the trick still has to be there in some form to be discovered. does' b' this mean that all the ideas we will ever have are already' b' pre-programmed into our brains? this is somewhat unlikely, given that' b' our brains ultimately are encoded in chromosomes worth of genetic' b" material, much of which isn't used." b'' b'indeed, this is extremely unlikely, given the vast impact of nurture' b'on our mind and brain. i suggest, however, that before trying to' b'understand our consciousness as a collection of algorithms.' b'' b'kevin, take a look at the references i mentioned, and think again.' b'i still think the best experts on the nature of a conscious mind' b'are neurologists, neuropsychologists and biologists (but do not' b'flame me for my opinions), since they study beings that are' b'conscious.' b'' b'the reason i am repeating my advice is that this discussion cannot' b'lead to anywhere if our backgrounds are too different.' b'' b'and please, do not bring qm into this discussion at all not' b'all physicists are happy with the claim that our consciousness' b"plays some special role in physics. i would say it doesn't." b'' b' the other problem with algorithms is their instability. not many' b' algorithms survive if you take out a large portion of their code, yet' b' people survive strokes without going completely haywire (there are' b' side-effects, but patients still seem remarkably stable.) also,' b' neurons in perfectly healthy people are dying at an alarming rate b" can an algorithm survive if i randomly corrupt various bits of it's" b' code?' b'' b"again, _brains are not computers_. don't forget this. this does not" b'mean they need something else to work they just work differently.' b"their primary 'purpose' is perception and guidance of action," b'self-awareness and high intelligence are later appearances.' b'' b' the next problem is the sticky question of "what is colour?" (replace' b" 'colour' with the sensation of your choice.) presumably, the" b" materialist viewpoint is that it's the product of some kind of" b' chemical reaction. the usual products of such a reaction are energy b' different chemicals. is colour a mixture of these?' b'' b"you are still expecting that we could find the idea of 'green' in" b'our brains somewhere, perhaps in the form of some chemical. this is' b"not how i see it. the sensation 'green' is a certain time-dependent" b'pattern in the area v4 of our visual cortex, and it is distributed' b'with the help of areas v1 and v2 to the rest of the brain.' b'' b'indeed, a firing pattern. i have sometimes thought of our consciousness' b'as a global free induction pattern of these local firing patterns,' b'but this is just idle speculation.' b'' b"scientific american's september issue was a special issue on" b'mind and brain. have you already read it from cover to cover? b'there are two articles on visual perception, so you might be' b'interested.' b'' b'but again, please note that subjective experiences cannot be' b'observed from a third-person perspective. if we see nothing but' b'neuronal activity, we cannot go on to conclude that this is not the' b'mind.' b'' b'kalat writes about numerous examples where electric stimulation' b'of different areas of brain have led to various changes in the' b"patients' state of mind. for instance, a patient whose septal area" b'was stimulated (without his knowledge) by remote control during' b'a psychiatric interview was quickly cured of his depression, and' b'started discussing a plan to seduce his girlfriend.' b'' b'stimulations in the temporal lobe have sometimes led to embarrassing' b'situations, when the patients have started flirting with the' b'therapist.' b'' b'in conclusion, there is evidence that' b'' b'1) brains are essentially necessary for subjective experiences,' b'brain damage is usually equivalent to some sort of mind damage' b'' b'2) conscious processes involve substantial brain activity in' b'various areas of brain when we think of colours, our' b'visual cortex is activated etc.' b'' b'3) consciousness is an afterthought we become conscious of our' b'actions with a half a second delay, and our brains are ahead' b"of our 'conscious will' by at least ms." b'' b'thus, i think it is fruitful to turn the question "why do \'i\' see' b'colours" around and ask "what is this \'i\' that seems to be' b'observing?", since it seems that our conscious mind is not' b'the king of our brains.' b'' b' if this is so, a' b" computer won't see colour, because the chemistry is different. does an" b' algorithm that sees colour have a selective advantage over an' b" equivalent that doesn't? it shouldn't, because the outputs of each" b' algorithm ought to be the same in equivalent circumstances. so why do' b' we see colour?' b'' b"this depends on what is meant by 'seeing colours'. does a neural" b'network that is capable of recognising handwritten numbers from' b'0 to see the numbers, if it is capable of sorting them?' b'' b'if you are asking, "why does an animal who is conscious of itself' b'as an observer have an evolutionary advantage over an animal who' b'doesn\'t", i have a good answer read my previous posting,' b'where i wrote why a sense of identity helps social animals to swap' b"roles and act more morally, so that they don't unconsciously" b'kill each other with newly discovered weapons. (a bit extreme,' b'but this is the basic idea.)' b'' b'when early _homo_ became more and more efficient in using tools,' b"a sense of identity and the concept of 'self' had to evolve in" b'line with this development. indeed, respect for others and' b'conscious altruistic behaviour might be evolutionary advantages' b'for social animals, such as early humans.' b'' b' if i remember correctly, quantum mechanics consists of a wavefunction,' b' with two processes acting on it. the first process has been called' b" 'unitary evolution' (or 'u'), is governed by schroedinger's equation" b' and is well known. the second process, called various things such as' b" 'collapse of the wavefunction' or 'state vector reduction' (or 'r')," b' and is more mysterious. it is usually said to occur when a' b" 'measurement' takes place, although nobody seems to know precisely" b' when that occurs. when it does occur, the effect of r is to abruptly' b' change the wavefunction.' b'' b'if minds are required for this, does this mean that until human' b'minds came to the scene, wavefunctions never collapsed, but remained' b'in the superpositions for aeons? my, how powerful we are.' b'' b'this has been discussed before, and i think this topic is irrelevant,' b'since we do not agree that minds are necessary, and neither do' b'physicists.' b'' b" anyway, i'm speculating that minds would be in part x. there seems to" b' be some link between consciousness and r, in that we never see linear' b' superpositions of anything, although there are alternative' b" explainations for this. i've no idea how a brain is supposed to access" b" part x, but since this is only speculation, that won't matter too" b' much my main point is that there might be a place for minds in' b' physics.' b'' b'i agree, but not in the sense you apparently mean above physics' b'needs sharp minds to solve many real problems. b'' b" i'll go back to my nice padded cell now, if that's ok with you b'' b"it's ok, if you don't forget to take with you the references i" b'wrote about in my previous posting, plus the following:' b'' b'kalat, james w. biological psychology.' b'3rd ed., wadsworth publishing company, belmont, ca b'' b'skarda, c. explaining behavior: bringing the brain back in.' b'inquiry b'' b'skarda, c. freeman, w. how brains make chaos in order to' b'make sense of the world.' b'behavioral and brain sciences b'' b'petri' b'' b'--' b"!___.'* pihatie c finou.oulu.fi physics is the rule of" b"*' finland phoenix.oulu.fi chemistry is the game." 